{
  "Flow": "Flow",
  "AddTab": "Add Tab",
  "ShowOnlyOutputs": "Show only outputs",
  "ShowOnlyParams": "Show only params",
  "ApiKeyRequiredMessage": "Please provide your API Key in the configuration settings to run your flow successfully.",
  "Prompt": "Prompt",
  "ClickToShowOutput": "Click to show output",
  "RoleInitPrompt": "Indicate the role you wish the AI to adopt in the upcoming interactions. For example, 'Behave as a Literary Critic'.",
  "EnterURL": "Web Extractor",
  "YoutubeTranscriptNodeName": "Youtube Transcript",
  "URLPlaceholder": "Input a URL",
  "Input": "Inputs",
  "InputImage": "Image",
  "InputPlaceholder": "Enter your text here to serve as input for other nodes.",
  "InputImagePlaceholder": "Enter the URL of the image you want to use.",
  "DALLE": "DALL-E",
  "ClickToShowImageOutput": "Click to show image output",
  "JsonView": "JSON View",
  "TopologicalView": "Outputs",
  "currentNodeView": "Current Node",
  "Upload": "Upload",
  "Download": "Download",
  "Text": "Text",
  "URL": "URL",
  "YoutubeVideo": "Youtube Transcript",
  "Models": "Models",
  "GPT": "GPT Model",
  "GPTPrompt": "GPT Prompt",
  "DataSplitter": "Data Splitter",
  "ReplicateModel": "Replicate",
  "NoContextPrompt": "GPT Prompt",
  "PromptPlaceholder": "Enter your prompt here, for example 'Create a Twitter thread based on the data I sent you.'",
  "MergePromptPlaceholder": "Enter your text for the merge, using ${input-1} and ${input-2} as placeholders. You can add additional text, for example: \n Answer to ${input-1} by considering ${input-2}.",
  "VisionPromptPlaceholder": "Please enter your prompt here to start the image analysis. For example, you could write 'Describe this image'",
  "VisionImageURLPlaceholder": "Enter the URL of the image you want to use.",
  "DallEPromptPlaceholder": "Enter your prompt here, for example 'A dog and a cat playing in the desert'",
  "ImageGeneration": "Image Generation",
  "AdvancedSection": "Advanced",
  "AiAction": "AI Action",
  "LLMPrompt": "GPT",
  "AiDataSplitter": "Data Splitter",
  "MergerNode": "Merge Text",
  "inputHelp": "This node is used to input text.",
  "inputImageHelp": "This node is used to input an image URL.",
  "urlInputHelp": "Enter a valid URL and the node will retrieve the data from this URL.",
  "youtubeTranscriptHelp": "This node retrieves the subtitles of a YouTube video from its URL.",
  "gptHelp": "This node allows you to configure a GPT model, specify its role, and the data it will use to respond.",
  "gptPromptHelp": "This node allows you to query a GPT model. It shares its context with other nodes connected to the model.",
  "noContextPromptHelp": "This node allows you to query GPT without context, just from input data and a prompt. You don't have to connect it to a GPT Model.",
  "dallePromptHelp": "This node uses the DALL-E model to generate images from a textual description.",
  "stableDiffusionPromptHelp": "This node uses the Stable Diffusion model to generate images from a textual description.",
  "stableVideoDiffusionPromptHelp": "This node uses Replicate to launch Stable Video Diffusion.",
  "aiActionPromptHelp": "This node uses GPT-4 to perform simple action, without having to write a prompt.",
  "llmPromtHelp": "This nodes allows you to send prompt to GPT-3.5 or GPT-4",
  "replicateHelp": "This nodes uses Replicate to give access to a large amount of models.",
  "mergerPromptHelp": "This nodes allows you to merge 2 inputs.",
  "gptVisionPromptHelp": "This node uses GPT-4 Vision and takes an image URL as input.",
  "dataSplitterHelp": "This node is used to split data into several parts. You can specify upstream how many parts you want to create. You can also run it individually so that it finds the exact number of outputs to generate.",
  "socketConnectionLost": "The connection has been lost.",
  "ClickToSelectModel": "Click to select model",
  "Or": "OR",
  "EnterModelNameDirectly": "Enter model name directly",
  "Load": "Load",
  "LoadMore": "Load more",
  "SpotlightModels": "Spotlight Models",
  "AllModels": "All Models",
  "EdgeType": "Edge type",
  "CannotChangeTabWhileRunning": "Cannot change tab while running",
  "EnterUrlToDesiredFile": "Enter file URL",
  "Transition": "Transition",
  "transitionHelp": "This node can be used to organize the flow.",
  "MissingFieldsMessage": "Required fields are missing",
  "Node": "Node",
  "MissingFields": "Missing fields",
  "CannotDeleteLastFlow": "Cannot delete the last flow",
  "HideSidebar": "Hide sidebar",
  "ShowSidebar": "Show sidebar",
  "fileUploadHelp": "This node can be used to load a file.",
  "llmPromptHelp": "This node allows you to send prompt to GPT-3.5 or GPT-4",
  "Output": "Output",
  "Inputs": "Inputs",
  "Parameters": "Parameters",
  "Duplicate": "Duplicate",
  "OpeninSidepane": "Open in sidepane",
  "ClearOutput": "Clear Output",
  "RemoveNode": "Remove Node",
  "ExpiredURL": "Expired URL",
  "NoNodeSelected": "No node selected yet.",
  "ClickOnNodeToSelectIt": "Click on any node to select it.",
  "Field": "Field",
  "DragAndDropNodes": "Drag and drop nodes onto the canvas to add them.",
  "CopiedToClipboard": "Copied to clipboard.",
  "DocumentToText": "Document-to-Text",
  "documentToTextHelp": "Convert .pdf .txt .csv .json .html file to simple text",
  "TextToSpeech": "Text-to-Speech",
  "textToSpeechHelp": "Convert a text to an audio file using OpenAI tts model",
  "error.upload_failed": "Upload failed. Please check your configuration to enable file upload.",
  "InputTextPlaceholder": "Enter your text here",
  "DownloadFile": "Download File",
  "FileUploaded": "File uploaded",
  "GenericPromptPlaceholder": "Enter your prompt here",
  "GenericNegativePromptPlaceholder": "Enter your negative prompt here",
  "EnterCustomName": "Enter custom name",
  "NodeColor": "Change node color",
  "ChangeName": "Change name",
  "RemoveFlow": "Remove flow",
  "HideHint": "Hide",
  "TextDocumentHint": "Please note that this node only provides files as URLs. To use a document (.pdf, .txt) in text format, consider using the 'Document-to-Text' node.",
  "Display": "Display",
  "displayHelp": "This resizable node allows you to display content.",
  "Validate": "Validate",
  "AI": "AI",
  "Separator": "Separator",
  "ClaudeAnthropic": "Claude",
  "claudeAnthropichHelp": "This node uses Claude from Anthropic to generate text.",
  "noDataAvailableForThisNode": "No data available for this node",
  "learnMore": "Learn more:",
  "Help": "Help",
  "cookiesConsentLabelPlaceholder": "Agree to all",
  "cookiesConsentLabelHelp": "For some pages, we need to click on the cookie consent button to access the data. This instruction helps locate the button.",
  "EditTextContent": "Edit text content",
  "ShowCoordinates": "Show Coordinates",
  "ShowNodesConfig": "Show Nodes Config",
  "DeleteAll": "Delete All",
  "DeleteOutputs": "Delete Outputs",
  "ReplaceText": "Replace Text",
  "ReplaceTextInputPlaceholder": "Enter the full text where the term will be replaced.",
  "ReplaceTextSearchPlaceholder": "Enter the term or regex pattern to be replaced.",
  "ReplaceTextReplacePlaceholder": "Enter the replacement term.",
  "replaceTextNodeHelp": "Use this node to find and replace specific text or patterns within the input.",
  "openaio1Help": "Advanced language models trained for complex reasoning, excelling in scientific, mathematical, and programming challenges.",
  "ContextPlaceholder": "Additionnal context that will be used to answer your prompt.",
  "deepSeekHelp": "Access DeepSeek LLMs through this node.",
  "openRouterHelp": "OpenRouter provides completion API to multiple models & providers. This nodes requires you to provide an API Key.",
  "Generate Number": "Generate Number",
  "generateNumberHelp": "Generate a random number",
  "httpGetProcessorURLPlaceholder": "Enter the URL to request",
  "httpGetProcessorURLDescription": "The URL that the HTTP GET request will be sent to.",
  "httpGetProcessorHeadersPlaceholder": "Enter headers in JSON format",
  "httpGetProcessorHeadersDescription": "The headers to include in the HTTP GET request.",
  "httpGetProcessorHelp": "Send an HTTP GET request with the specified headers.",
  "gptImageHelp": "Generate or Edit an image using GPT Image",
  "gptImageMaskDescription": "You can provide a mask to indicate where the image should be edited. You can use the prompt to describe the full new image, not just the erased area. If you provide multiple input images, the mask will be applied to the first image.",
  "dallEDeprecated": "Most recent OpenAI models are now available via the new GPT Image node and are superior to DALL-E. DALL-E remains available if needed.",
  "TTSInstructionPlaceholder": "Ex : Speak in a cheerful and positive tone.",
  "TTSInstructionDescription": " Prompt the model to control aspects of speech (accent, emotional range, intonation, speed, tone, ...)",
  "PopularModels": "Popular Models",
  "removeBackgroundDescription": "Remove the background from an image using the StabilityAI API.",
  "upscaleFastDescription": "Upscale an image using StabilityAI API",
  "fluxDescription": "Generate an image using the FLUX model.",
  "fluxKontextDescription": "A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language",
  "faceswapDescription": "Seamlessly swap faces between images, allowing for realistic and precise facial replacements.",
  "removeBgDescription": "Remove the background from an image using lucataco/remove-bg from Replicate API.",
  "upscaleDescription": "Real-ESRGAN with optional face correction and adjustable upscale",
  "GoogleUpscaleDescription": "Upscale an image using Google's model.",
  "moondreamDescription": "Moondream is a vision model that responds to prompts about a given image.",
  "llamaDescription": "Meta's flagship 405 billion parameter language model, fine-tuned for chat completions.",
  "imagenDescription": "Imagen produce stunning, detailed images with precision.",
  "recraftSVGDescription": "Recraft SVG offers advanced vector image generation, enabling scalable and creative SVG designs.",
  "recraftDescription": "Recraft V3 is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. ",
  "video01Description": "Video-01 provides dynamic video generation.",
  "video01LiveDescription": "Video-01-Live provides dynamic video generation, ideal for 2D animation.",
  "klingDescription": "Kling delivers robust video generation and animation solutions, available in both professional and standard versions.",
  "veo3Description": "Googleâ€™s flagship Veo 3 text to video model, with audio"
}
